{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9ZT3MI3-gF6"
   },
   "source": [
    "#Demo 3 - Analyze feature contributions in Ensemble Models\n",
    "##**Scenario: Predicting Customer Churn in a Subscription Service**\n",
    "\n",
    "A video streaming company wants to optimize ensemble machine learning models (like Random Forest and Gradient Boosting) for predicting customer churn. Beyond achieving high accuracy, the team wants to understand which hyperparameters most influence model performance â€” so they can design efficient tuning strategies.\n",
    "\n",
    "\n",
    "\n",
    "##**Objective:**\n",
    "Analyze feature contributions in ensemble models to explain the underlying reasons for customer churn. By quantifying the importance and influence of different input features (e.g., number of support calls, payment issues, subscription type), the business aims to:\n",
    "\n",
    "* Identify key drivers of churn.\n",
    "\n",
    "* Take targeted actions (e.g., better support, loyalty rewards).\n",
    "\n",
    "* Communicate model findings to non-technical stakeholders.\n",
    "\n",
    "* Build trust in predictive models through interpretable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PE6x9rIJjUy"
   },
   "source": [
    "## Step 1: Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsKQIVvVAuBl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXgnDP8eJglP"
   },
   "source": [
    "## Step 2: Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nj8kOeVUJeXS"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"customer_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dNCrgOlJdVm"
   },
   "source": [
    "## Step 3: Encoding Categorical Variables\n",
    " Encode 'ContractType' into numerical format (e.g., Monthly = 1, Yearly = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RQITRb5JcNe"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"ContractType\"] = le.fit_transform(df[\"ContractType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlWf7J62JZCO"
   },
   "source": [
    "## Step 4: Preparing Feature Matrix (X) and Target Vector (y)\n",
    " Drop irrelevant columns and set target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nBhOTVcJXkO"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"CustomerID\", \"Churn\"])\n",
    "y = df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NafC6ZjiJURh"
   },
   "source": [
    "## Step 5: Splitting the Dataset\n",
    " Split into train and test sets (80% train, 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCCOFjsbJTy-"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_FppxZhJRWC"
   },
   "source": [
    "## Step 6: Defining Hyperparameter Grid\n",
    " These are the hyperparameters we want to evaluate for their contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkkF7msTJQsW"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_lrx0rjJOUa"
   },
   "source": [
    "##Step 7: Running Grid Search with Cross-Validation\n",
    " This will train models for all hyperparameter combinations and evaluate their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWhlj6suJN0-"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87ZoVppKJLIf"
   },
   "source": [
    "## Step 8: Evaluating the Best Model\n",
    "Get the best performing hyperparameter combination and evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leMuALbVJKOU"
   },
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters Found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoevnhCsJHgj"
   },
   "source": [
    "## Step 9: Analyzing Hyperparameter Contribution via Grid Scores\n",
    "Convert grid search results to DataFrame for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTvTgwxKJHYD"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Select relevant columns for hyperparameters and mean test scores\n",
    "param_cols = [col for col in results_df.columns if col.startswith('param_')]\n",
    "score_col = 'mean_test_score'\n",
    "\n",
    "# Sort and display top 10 configurations\n",
    "sorted_results = results_df[param_cols + [score_col]].sort_values(by=score_col, ascending=False)\n",
    "print(\"\\nTop 10 Hyperparameter Combinations by Accuracy:\")\n",
    "print(sorted_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0GBnVfRJFSm"
   },
   "source": [
    "## Step 10: Visualizing Interaction Between Two Hyperparameters Using Heatmap\n",
    "Here we analyze how combinations of max_depth and min_samples_split affect model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Er5LoIzbJD62"
   },
   "outputs": [],
   "source": [
    "# Pivot the results into a 2D heatmap-friendly format\n",
    "heatmap_data = results_df.pivot_table(\n",
    "    index='param_max_depth',\n",
    "    columns='param_min_samples_split',\n",
    "    values='mean_test_score'\n",
    ")\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Hyperparameter Interaction: max_depth vs min_samples_split\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
