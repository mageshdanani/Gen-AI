{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Demo 2: Scaling Features Using StandardScaler and MinMaxScaler from Scikit-learn\n",
        "\n",
        "\n",
        "##**Scenario: Loan Eligibility Prediction**\n",
        "\n",
        "A banking institution wants to develop a machine learning model to predict whether a loan applicant is eligible for a loan. The dataset contains customer financial details, such as income, loan amount, credit score, and debt-to-income ratio. However, these features have different scales:\n",
        "\n",
        "* Income is in thousands of dollars (e.g., 30,000 to 150,000).\n",
        "\n",
        "* Loan Amount ranges from a few thousand to hundreds of thousands.\n",
        "\n",
        "* Credit Score is typically between 300 and 850.\n",
        "\n",
        "* Debt-to-Income Ratio is a decimal between 0 and 1.\n",
        "\n",
        "Since machine learning models perform poorly when features have different scales, proper feature scaling is necessary to ensure fair weightage and better convergence in optimization.\n",
        "\n",
        "##**Objective**\n",
        "* Apply StandardScaler (Z-score normalization) to transform data into a standard distribution with mean 0 and variance 1.\n",
        "\n",
        "* Apply MinMaxScaler (Min-Max normalization) to scale features between 0 and 1, preserving the relative distribution.\n",
        "\n",
        "* Compare the effect of different scaling techniques on data distribution and machine learning performance."
      ],
      "metadata": {
        "id": "LmhuHqmwTi0H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoYniM71TJIB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"loan_eligibility_dataset.csv\")\n",
        "\n",
        "# Display first few rows to understand the dataset\n",
        "print(\"Initial Dataset:\\n\", df.head())"
      ],
      "metadata": {
        "id": "BjEL5VQZUOy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting numerical columns for scaling\n",
        "numerical_features = [\"Income\", \"LoanAmount\", \"CreditScore\", \"DebtToIncomeRatio\"]"
      ],
      "metadata": {
        "id": "-0ugDvojUQUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting only numerical features for scaling\n",
        "df_numerical = df[numerical_features]"
      ],
      "metadata": {
        "id": "XN_spWLOUTQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize StandardScaler\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "# Apply StandardScaler transformation\n",
        "df_standard_scaled = standard_scaler.fit_transform(df_numerical)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "df_standard_scaled = pd.DataFrame(df_standard_scaled, columns=numerical_features)"
      ],
      "metadata": {
        "id": "EJQSeIMZUWmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display scaled data\n",
        "print(\"\\nStandard Scaled Data (Z-score normalization):\\n\", df_standard_scaled.head())"
      ],
      "metadata": {
        "id": "z5HyYdsOUY9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# Apply MinMaxScaler transformation\n",
        "df_minmax_scaled = minmax_scaler.fit_transform(df_numerical)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "df_minmax_scaled = pd.DataFrame(df_minmax_scaled, columns=numerical_features)"
      ],
      "metadata": {
        "id": "IG1JfkPvUab4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display scaled data\n",
        "print(\"\\nMin-Max Scaled Data (Range 0-1):\\n\", df_minmax_scaled.head())"
      ],
      "metadata": {
        "id": "matx6dijUgK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Standard Scaled dataset\n",
        "df_standard_scaled.to_csv(\"standard_scaled_loan_data.csv\", index=False)\n",
        "\n",
        "# Save Min-Max Scaled dataset\n",
        "df_minmax_scaled.to_csv(\"minmax_scaled_loan_data.csv\", index=False)\n",
        "\n",
        "print(\"\\nScaled datasets saved as 'standard_scaled_loan_data.csv' and 'minmax_scaled_loan_data.csv'\")"
      ],
      "metadata": {
        "id": "BHg_yk1pUiYV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}